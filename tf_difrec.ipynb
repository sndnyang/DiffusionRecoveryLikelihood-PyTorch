{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.2.0 tensorflow-addons==0.10.0 tensorflow_io==0.14.0 matplotlib Pillow tensorflow-probability==0.9.0 tensorflow-datasets==3.0.0\n",
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.7.0'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import tensorflow.experimental.numpy as tnp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "ds = datasets.get_dataset('cifar10', tfds_data_dir='tensorflow_datasets')\n",
    "img_sz = ds._img_size\n",
    "n_train = ds.num_train_examples\n",
    "ds = ds.train_input_fn({'batch_size': 256})\n",
    "\n",
    "ds_iter = iter(ds)\n",
    "\n",
    "from datasets import data_preprocess\n",
    "data = next(ds_iter)\n",
    "x = data_preprocess(data['image'])\n",
    "labels = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\project\\douyinv\\venv\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:54: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.7.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_addons as tfa\n",
    "import nn\n",
    "\n",
    "\n",
    "def nonlinearity(x):\n",
    "    if FLAGS.act == 'lrelu':\n",
    "        return tf.nn.leaky_relu(x)\n",
    "    if FLAGS.act == 'swish':\n",
    "        return tf.nn.swish(x)\n",
    "\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "class normalize(tf.keras.layers.Layer):\n",
    "    def __init__(self, name, *args, **kwargs):\n",
    "        super(normalize, self).__init__(name=name, *args, **kwargs)\n",
    "        if FLAGS.normalize:\n",
    "            if FLAGS.normalize == 'group_norm':\n",
    "                self.norm = tfa.layers.GroupNormalization(groups=32, epsilon=1e-06)\n",
    "            elif FLAGS.normalize == 'batch_norm':\n",
    "                self.norm = tf.keras.layers.BatchNormalization()\n",
    "            elif FLAGS.normalize == 'instance_norm':\n",
    "                self.norm = tfa.layers.InstanceNormalization()\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if FLAGS.normalize:\n",
    "            inputs = self.norm(inputs, training=True)\n",
    "        return inputs\n",
    "\n",
    "\n",
    "class downsample(tf.keras.layers.Layer):\n",
    "    def __init__(self, name, with_conv, *args, **kwargs):\n",
    "        super(downsample, self).__init__(name=name, *args, **kwargs)\n",
    "        self.with_conv = with_conv\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        B, H, W, C = input_shape\n",
    "        if self.with_conv:\n",
    "            self.conv2d = nn.conv2d(name='conv', num_units=C, filter_size=3, stride=2, spec_norm=FLAGS.spec_norm)\n",
    "        # print('{}: x={}'.format(self.name, input_shape))\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        B, H, W, C = inputs.shape\n",
    "\n",
    "        if self.with_conv:\n",
    "            x = self.conv2d(inputs)\n",
    "        else:\n",
    "            x = tf.nn.avg_pool(inputs, 2, 2, 'SAME')\n",
    "        assert x.shape == [B, H // 2, W // 2, C]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class resnet_block(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, name, out_ch=None):\n",
    "        super(resnet_block, self).__init__(name=name)\n",
    "        self.out_ch = out_ch\n",
    "        self.conv_shortcut = FLAGS.res_conv_shortcut\n",
    "        self.spec_norm = FLAGS.spec_norm\n",
    "        self.use_scale = FLAGS.res_use_scale\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        B, H, W, C = input_shape\n",
    "        if self.out_ch is None:\n",
    "            self.out_ch = C\n",
    "        self.normalize_1 = normalize('norm1')\n",
    "        self.normalize_2 = normalize('norm2')\n",
    "\n",
    "        self.dense = nn.dense(name='temb_proj', num_units=self.out_ch, spec_norm=self.spec_norm)\n",
    "        self.conv2d_1 = nn.conv2d(name='conv1', num_units=self.out_ch, spec_norm=self.spec_norm)\n",
    "\n",
    "        self.conv2d_2 = nn.conv2d(\n",
    "            name='conv2', num_units=self.out_ch, init_scale=0., spec_norm=self.spec_norm, use_scale=self.use_scale\n",
    "        )\n",
    "        if self.conv_shortcut:\n",
    "            self.conv2d_shortcut = nn.conv2d(name='conv_shortcut', num_units=self.out_ch, spec_norm=self.spec_norm)\n",
    "        else:\n",
    "            self.nin_shortcut = nn.nin(name='nin_shortcut', num_units=self.out_ch, spec_norm=self.spec_norm)\n",
    "        # print('{}: x={}'.format(self.name, input_shape))\n",
    "\n",
    "    def call(self, inputs, temb=None, dropout=0.):\n",
    "        B, H, W, C = inputs.shape\n",
    "        x = inputs\n",
    "        h = inputs\n",
    "\n",
    "        h = nonlinearity(self.normalize_1(h))\n",
    "        h = self.conv2d_1(h)\n",
    "\n",
    "        if temb is not None:\n",
    "\n",
    "            # add in timestep embedding\n",
    "            temp_o = self.dense(nonlinearity(temb))\n",
    "            # print(h.shape, temp_o.shape)\n",
    "            h += temp_o[:, None, None, :]\n",
    "\n",
    "        h = nonlinearity(self.normalize_2(h))\n",
    "        h = tf.nn.dropout(h, rate=dropout)\n",
    "        h = self.conv2d_2(h)\n",
    "\n",
    "        if C != self.out_ch:\n",
    "            if self.conv_shortcut:\n",
    "                x = self.conv2d_shortcut(x)\n",
    "            else:\n",
    "                x = self.nin_shortcut(x)\n",
    "\n",
    "        assert x.shape == h.shape\n",
    "        return x + h\n",
    "\n",
    "\n",
    "class attn_block(tf.keras.layers.Layer):\n",
    "    def __init__(self, name):\n",
    "        super(attn_block, self).__init__(name=name)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        B, H, W, C = input_shape\n",
    "        self.normalize = normalize(name='norm')\n",
    "        self.nin_q = nn.nin(name='q', num_units=C)\n",
    "        self.nin_k = nn.nin(name='k', num_units=C)\n",
    "        self.nin_v = nn.nin(name='v', num_units=C)\n",
    "\n",
    "        self.nin_proj_out = nn.nin(name='proj_out', num_units=C, init_scale=0.)\n",
    "        # print('{}: x={}'.format(self.name, input_shape))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        B, H, W, C = x.shape\n",
    "\n",
    "        h = self.normalize(x)\n",
    "        q = self.nin_q(h)\n",
    "        k = self.nin_k(h)\n",
    "        v = self.nin_v(h)\n",
    "\n",
    "        w = tf.einsum('bhwc,bHWc->bhwHW', q, k) * (int(C) ** (-0.5))\n",
    "        w = tf.reshape(w, [B, H, W, H * W])\n",
    "        w = tf.nn.softmax(w, -1)\n",
    "        w = tf.reshape(w, [B, H, W, H, W])\n",
    "\n",
    "        h = tf.einsum('bhwHW,bHWc->bhwc', w, v)\n",
    "        h = self.nin_proj_out(h)\n",
    "\n",
    "        assert h.shape == x.shape\n",
    "\n",
    "        return x + h\n",
    "\n",
    "\n",
    "class net_res_temb2(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, name, ch, ch_mult=(1, 2, 4, 8), num_res_blocks,\n",
    "                 attn_resolutions, num_classes=10):\n",
    "        super(net_res_temb2, self).__init__(name=name)\n",
    "        self.ch, self.ch_mult = ch, ch_mult\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        self.attn_resolutions = attn_resolutions\n",
    "        self.num_resolutions = len(self.ch_mult)\n",
    "        self.resamp_with_conv = FLAGS.resamp_with_conv\n",
    "        self.use_attention = FLAGS.use_attention\n",
    "        self.spec_norm = FLAGS.spec_norm\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # timestep embedding\n",
    "        self.temb_dense_0 = nn.dense(name='temb/dense0', num_units=self.ch * 4, spec_norm=self.spec_norm)\n",
    "        self.temb_dense_1 = nn.dense(name='temb/dense1', num_units=self.ch * 4, spec_norm=self.spec_norm)\n",
    "        self.temb_dense_2 = nn.dense(name='temb/dense2', num_units=self.ch * self.ch_mult[-1], spec_norm=False)\n",
    "\n",
    "        self.linear = nn.dense(name='classifier', num_units=self.num_classes, spec_norm=False)\n",
    "\n",
    "        S = input_shape[-3]\n",
    "        self.res_levels = []\n",
    "        self.attn_s = dict()\n",
    "        self.downsample_s = []\n",
    "\n",
    "        # downsample\n",
    "        self.conv2d_in = nn.conv2d(name='conv_in', num_units=self.ch, spec_norm=self.spec_norm)\n",
    "        for i_level in range(self.num_resolutions):\n",
    "            res_s = []\n",
    "            if self.use_attention and S in self.attn_resolutions:\n",
    "                self.attn_s[str(S)] = []\n",
    "            for i_block in range(self.num_res_blocks):\n",
    "                res_s.append(\n",
    "                    resnet_block(\n",
    "                        name='level_{}_block_{}'.format(i_level, i_block), out_ch=self.ch * self.ch_mult[i_level]\n",
    "                    )\n",
    "                )\n",
    "                if self.use_attention and S in self.attn_resolutions:\n",
    "                    self.attn_s[str(S)].append(attn_block(name='down_{}_attn_{}'.format(i_level, i_block)))\n",
    "            self.res_levels.append(res_s)\n",
    "\n",
    "            if i_level != self.num_resolutions - 1:\n",
    "                self.downsample_s.append(downsample(name='downsample_{}'.format(i_level), with_conv=self.resamp_with_conv))\n",
    "                S = S // 2\n",
    "\n",
    "        # end\n",
    "        self.normalize_out = normalize(name='norm_out')\n",
    "        self.fc_out = nn.dense(name='dense_out', num_units=1, spec_norm=False)\n",
    "\n",
    "    def call(self, inputs, t, dropout):\n",
    "        x = inputs\n",
    "        B, S, _, _ = x.shape\n",
    "        assert x.dtype == tf.float32 and x.shape[2] == S\n",
    "        if isinstance(t, int) or len(t.shape) == 0:\n",
    "            t = tf.ones([B], dtype=tf.int32) * t\n",
    "\n",
    "        # Timestep embedding\n",
    "        temb = nn.get_timestep_embedding(t, self.ch)\n",
    "\n",
    "        temb = self.temb_dense_0(temb)\n",
    "\n",
    "        temb = self.temb_dense_1(nonlinearity(temb))\n",
    "\n",
    "        assert temb.shape == [B, self.ch * 4]\n",
    "\n",
    "        # downsample\n",
    "        h = self.conv2d_in(x)\n",
    "        for i_level in range(self.num_resolutions):\n",
    "            for i_block in range(self.num_res_blocks):\n",
    "                h = self.res_levels[i_level][i_block](h, temb=temb, dropout=dropout)\n",
    "\n",
    "                if self.use_attention:\n",
    "                    if h.shape[1] in self.attn_resolutions:\n",
    "                        h = self.attn_s[str(h.shape[1])][i_block](h)\n",
    "\n",
    "            if i_level != self.num_resolutions - 1:\n",
    "                h = self.downsample_s[i_level](h)\n",
    "\n",
    "        # end\n",
    "        if FLAGS.final_act == 'relu':\n",
    "            h = tf.nn.relu(h)\n",
    "        elif FLAGS.final_act == 'swish':\n",
    "            h = tf.nn.swish(h)\n",
    "        elif FLAGS.final_act == 'lrelu':\n",
    "            tf.nn.leaky_relu(x)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        h = tf.reduce_sum(h, [1, 2])\n",
    "        temb_final = self.temb_dense_2(nonlinearity(temb))\n",
    "        feature = h * temb_final\n",
    "        logits = self.linear(feature)\n",
    "        h = tf.reduce_sum(feature, axis=1)\n",
    "\n",
    "        return h, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "FLAGS = argparse.Namespace()\n",
    "FLAGS.act = 'lrelu'\n",
    "FLAGS.normalize = None\n",
    "FLAGS.res_conv_shortcut = True\n",
    "FLAGS.spec_norm = True\n",
    "FLAGS.res_use_scale = True\n",
    "FLAGS.resamp_with_conv = False\n",
    "FLAGS.use_attention = False\n",
    "FLAGS.final_act = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_mult = (1, 2, 2, 2)\n",
    "net = net_res_temb2(name='net', ch=128, ch_mult=ch_mult, num_res_blocks=2, attn_resolutions=(16,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\research\\EBM\\difrec\\nn.py:90: The name tf.keras.initializers.TruncatedNormal is deprecated. Please use tf.compat.v1.keras.initializers.TruncatedNormal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\research\\EBM\\difrec\\nn.py:90: The name tf.keras.initializers.TruncatedNormal is deprecated. Please use tf.compat.v1.keras.initializers.TruncatedNormal instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "TensorShape([64])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform([64, 32, 32, 3], minval=-.5, maxval=.5)\n",
    "t = tf.random.uniform(shape=[64], maxval=6, dtype=tf.int32)\n",
    "out = net(x, t, 0)[0]\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "DEFAULT_DTYPE = tf.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,) (63,)\n",
      "(64, 126)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 127])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_timestep_embedding(timesteps, embedding_dim: int):\n",
    "    \"\"\"\n",
    "    From Fairseq.\n",
    "    Build sinusoidal embeddings.\n",
    "    This matches the implementation in tensor2tensor, but differs slightly\n",
    "    from the description in Section 3.5 of \"Attention Is All You Need\".\n",
    "    \"\"\"\n",
    "    assert len(timesteps.shape) == 1  # and timesteps.dtype == tf.int32\n",
    "\n",
    "    half_dim = embedding_dim // 2\n",
    "\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = tf.exp(tf.range(half_dim, dtype=DEFAULT_DTYPE) * -emb)\n",
    "    print(timesteps.shape, emb.shape)\n",
    "    # emb = tf.range(num_embeddings, dtype=DEFAULT_DTYPE)[:, None] * emb[None, :]\n",
    "    emb = tf.cast(timesteps, dtype=DEFAULT_DTYPE)[:, None] * emb[None, :]\n",
    "\n",
    "    emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=1)\n",
    "    print(emb.shape)\n",
    "    if embedding_dim % 2 == 1:  # zero pad\n",
    "        # emb = tf.concat([emb, tf.zeros([num_embeddings, 1])], axis=1)\n",
    "        emb = tf.pad(emb, [[0, 0], [0, 1]])\n",
    "    assert emb.shape == [timesteps.shape[0], embedding_dim]\n",
    "    return emb\n",
    "\n",
    "t = tf.random.uniform(shape=[64], maxval=6, dtype=tf.int32)\n",
    "temb = get_timestep_embedding(t, 127)\n",
    "temb.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recovery Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf\n",
    "\n",
    "\n",
    "def get_beta_schedule(*, beta_start, beta_end, num_diffusion_timesteps):\n",
    "    betas = np.linspace(beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64)\n",
    "    betas = np.append(betas, 1.)\n",
    "    assert betas.shape == (num_diffusion_timesteps + 1,)\n",
    "\n",
    "\n",
    "    return betas\n",
    "\n",
    "\n",
    "def get_sigma_schedule(*, beta_start, beta_end, num_diffusion_timesteps):\n",
    "    \"\"\"\n",
    "    Get the noise level schedule\n",
    "    :param beta_start: begin noise level\n",
    "    :param beta_end: end noise level\n",
    "    :param num_diffusion_timesteps: number of timesteps\n",
    "    :return:\n",
    "    -- sigmas: sigma_{t+1}, scaling parameter of epsilon_{t+1}\n",
    "    -- a_s: sqrt(1 - sigma_{t+1}^2), scaling parameter of x_t\n",
    "    \"\"\"\n",
    "    betas = np.linspace(beta_start, beta_end, 1000, dtype=np.float64)\n",
    "    betas = np.append(betas, 1.)\n",
    "    assert isinstance(betas, np.ndarray)\n",
    "    betas = betas.astype(np.float64)\n",
    "    assert (betas > 0).all() and (betas <= 1).all()\n",
    "    sqrt_alphas = np.sqrt(1. - betas)\n",
    "    idx = tf.cast(np.concatenate([np.arange(num_diffusion_timesteps) * (1000 // ((num_diffusion_timesteps - 1) * 2)), [999]]), dtype=tf.int32)\n",
    "    a_s = np.concatenate(\n",
    "        [[np.prod(sqrt_alphas[: idx[0] + 1])],\n",
    "         np.asarray([np.prod(sqrt_alphas[idx[i - 1] + 1: idx[i] + 1]) for i in np.arange(1, len(idx))])])\n",
    "    sigmas = np.sqrt(1 - a_s ** 2)\n",
    "\n",
    "    return sigmas, a_s\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "\n",
    "class RecoveryLikelihood(tf.keras.Model):\n",
    "    def __init__(self, hps):\n",
    "        super(RecoveryLikelihood, self).__init__()\n",
    "        self.hps = hps\n",
    "        self.num_timesteps = FLAGS.num_diffusion_timesteps\n",
    "\n",
    "        self.sigmas, self.a_s = get_sigma_schedule(beta_start=0.0001, beta_end=0.02, num_diffusion_timesteps=self.num_timesteps)\n",
    "        self.a_s_cum = np.cumprod(self.a_s)\n",
    "        self.sigmas_cum = np.sqrt(1 - self.a_s_cum ** 2)\n",
    "        self.a_s_prev = self.a_s.copy()\n",
    "        self.a_s_prev[-1] = 1\n",
    "        self.is_recovery = np.ones(self.num_timesteps + 1, dtype=np.float32)\n",
    "        self.is_recovery[-1] = 0\n",
    "        centers = torch.load('../%s_one_mean.pt' % hps.problem)\n",
    "        covs = torch.load('../%s_one_cov.pt' % hps.problem)\n",
    "        size = [3, 32, 32]\n",
    "        self.dist = MultivariateNormal(centers, covariance_matrix=covs + 1e-4 * torch.eye(int(np.prod(size))))\n",
    "\n",
    "        if self.hps.img_sz == 32:\n",
    "            ch_mult = (1, 2, 2, 2)\n",
    "        elif self.hps.img_sz == 128:\n",
    "            ch_mult = (1, 2, 2, 2, 4, 4)\n",
    "        elif self.hps.img_sz == 64:\n",
    "            ch_mult = (1, 2, 2, 2, 4)\n",
    "        elif self.hps.img_sz == 256:\n",
    "            ch_mult = (1, 1, 2, 2, 2, 4, 4,)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.net = net_res_temb2(name='net', ch=128, ch_mult=ch_mult, num_res_blocks=FLAGS.num_res_blocks, attn_resolutions=(16,))\n",
    "\n",
    "    def init(self, x_shape):\n",
    "        \"\"\"\n",
    "        Initialization function to activate model weights.\n",
    "        :param x_shape: input date shape\n",
    "        \"\"\"\n",
    "        x = tf.random.uniform(x_shape, minval=-.5, maxval=.5)\n",
    "        self.net(x, 0, dropout=0.)\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract(a, t, x_shape):\n",
    "        \"\"\"\n",
    "        Extract some coefficients at specified timesteps,\n",
    "        then reshape to [batch_size, 1, 1, 1, 1, ...] for broadcasting purposes.\n",
    "        \"\"\"\n",
    "        if isinstance(t, int) or len(t.shape) == 0:\n",
    "            t = tf.ones(x_shape[0], dtype=tf.int32) * t\n",
    "        bs, = t.shape\n",
    "        assert x_shape[0] == bs\n",
    "        out = tf.gather(tf.convert_to_tensor(a, dtype=tf.float32), t)\n",
    "        assert out.shape == [bs]\n",
    "        return tf.reshape(out, [bs] + ((len(x_shape) - 1) * [1]))\n",
    "\n",
    "    def q_sample(self, x_start, t, *, noise=None):\n",
    "        \"\"\"\n",
    "        Diffuse the data (t == 0 means diffused for 1 step)\n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = tf.random.normal(shape=x_start.shape)\n",
    "            # noise = self.dist.sample((x_start.shape[0],)).view((-1, 3, x_start.shape[2], x_start.shape[2])).permute((0, 2, 3, 1)).numpy()\n",
    "        assert noise.shape == x_start.shape\n",
    "        x_t = self._extract(self.a_s_cum, t, x_start.shape) * x_start +\n",
    "        self._extract(self.sigmas_cum, t, x_start.shape) * noise\n",
    "\n",
    "    return x_t\n",
    "\n",
    "def q_sample_pairs(self, x_start, t):\n",
    "    \"\"\"\n",
    "    Generate a pair of disturbed images for training\n",
    "    :param x_start: x_0\n",
    "    :param t: time step t\n",
    "    :return: x_t, x_{t+1}\n",
    "    \"\"\"\n",
    "    noise = tf.random.normal(shape=x_start.shape)\n",
    "    # noise = self.dist.sample((x_start.shape[0],)).view((-1, 3, x_start.shape[2], x_start.shape[2])).permute((0, 2, 3, 1)).numpy()\n",
    "    x_t = self.q_sample(x_start, t)\n",
    "    x_t_plus_one = self._extract(self.a_s, t+1, x_start.shape) * x_t +\n",
    "    self._extract(self.sigmas, t+1, x_start.shape) * noise\n",
    "\n",
    "return x_t, x_t_plus_one, noise\n",
    "\n",
    "def q_sample_progressive(self, x_0):\n",
    "    \"\"\"\n",
    "    Generate a full sequence of disturbed images\n",
    "    \"\"\"\n",
    "    x_preds = []\n",
    "    for t in range(self.num_timesteps + 1):\n",
    "        t_now = tf.ones([x_0.shape[0]], dtype=tf.int32) * t\n",
    "        x = self.q_sample(x_0, t_now)\n",
    "        x_preds.append(x)\n",
    "    x_preds = tf.stack(x_preds, axis=0)\n",
    "\n",
    "    return x_preds\n",
    "\n",
    "# === Training loss ===\n",
    "def training_losses(self, x_pos, x_neg, t, *, dropout=0.):\n",
    "    \"\"\"\n",
    "    Training loss calculation\n",
    "    \"\"\"\n",
    "    a_s = self._extract(self.a_s_prev, t + 1, x_pos.shape)\n",
    "    y_pos = a_s * x_pos\n",
    "    y_neg = a_s * x_neg\n",
    "    pos_f = self.net(y_pos, t, dropout=dropout)[0]\n",
    "    neg_f = self.net(y_neg, t, dropout=dropout)[0]\n",
    "    loss = - (pos_f - neg_f)\n",
    "\n",
    "    loss_scale = 1.0 / (tf.cast(tf.gather(self.sigmas, t + 1), tf.float32) / self.sigmas[1])\n",
    "    loss = loss_scale * loss\n",
    "\n",
    "    loss_ts = tf.math.unsorted_segment_mean(tf.abs(loss), t, self.num_timesteps)\n",
    "    f_ts = tf.math.unsorted_segment_mean(tf.abs(pos_f), t, self.num_timesteps)\n",
    "\n",
    "    return tf.nn.compute_average_loss(loss, global_batch_size=self.hps.n_batch_train), loss_ts, f_ts\n",
    "\n",
    "def log_prob(self, y, t, tilde_x, b0, sigma, is_recovery, *, dropout):\n",
    "    return self.net(y, t, dropout=dropout)[0] / tf.reshape(b0, [-1]) - tf.reduce_sum((y - tilde_x) ** 2 / 2 / sigma ** 2 * is_recovery, axis=[1, 2, 3])\n",
    "\n",
    "def grad_f(self, y, t, tilde_x, b0, sigma, is_recovery, *, dropout):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(y)\n",
    "        log_p_y = self.log_prob(y, t, tilde_x, b0, sigma, is_recovery, dropout=dropout)\n",
    "    grad_y = tape.gradient(log_p_y, y)\n",
    "    return grad_y, log_p_y\n",
    "\n",
    "# === Sampling ===\n",
    "def p_sample_langevin(self, tilde_x, t, *, dropout):\n",
    "    \"\"\"\n",
    "    Langevin sampling function\n",
    "    \"\"\"\n",
    "    sigma = self._extract(self.sigmas, t + 1, tilde_x.shape)\n",
    "    sigma_cum = self._extract(self.sigmas_cum, t, tilde_x.shape)\n",
    "    is_recovery = self._extract(self.is_recovery, t + 1, tilde_x.shape)\n",
    "    a_s = self._extract(self.a_s_prev, t + 1, tilde_x.shape)\n",
    "\n",
    "    c_t_square = sigma_cum / self.sigmas_cum[0]\n",
    "    step_size_square = c_t_square * self.hps.mcmc_step_size_b_square * sigma ** 2\n",
    "\n",
    "    y = tf.identity(tilde_x)\n",
    "    is_accepted_summary = tf.zeros(y.shape[0], dtype=tf.float32)\n",
    "    grad_y, log_p_y = self.grad_f(y, t, tilde_x, step_size_square, sigma, is_recovery, dropout=dropout)\n",
    "\n",
    "    for _ in tf.range(tf.convert_to_tensor(self.hps.mcmc_num_steps)):\n",
    "        noise = tf.random.normal(y.shape)\n",
    "        # noise = self.dist.sample((y.shape[0], )).view(y.shape.as_list()).numpy()\n",
    "        y_new = y + 0.5 * step_size_square * grad_y + tf.sqrt(step_size_square) * noise * FLAGS.noise_scale\n",
    "\n",
    "        grad_y_new, log_p_y_new = self.grad_f(y_new, t, tilde_x, step_size_square, sigma, is_recovery, dropout=dropout)\n",
    "        y, grad_y, log_p_y = y_new, grad_y_new, log_p_y_new\n",
    "\n",
    "    is_accepted_summary = is_accepted_summary / tf.convert_to_tensor(self.hps.mcmc_num_steps, dtype=tf.float32)\n",
    "    is_accepted_summary = tf.reduce_mean(is_accepted_summary)\n",
    "\n",
    "    x = y / a_s\n",
    "\n",
    "    disp = tf.math.unsorted_segment_mean(\n",
    "        tf.norm(tf.reshape(x, [x.shape[0], -1]) - tf.reshape(tilde_x, [tilde_x.shape[0], -1]), axis=1),\n",
    "        t, self.num_timesteps)\n",
    "\n",
    "    return x, disp, is_accepted_summary\n",
    "\n",
    "@tf.function\n",
    "def p_sample_progressive(self, noise):\n",
    "    \"\"\"\n",
    "    Sample a sequence of images with the sequence of noise levels\n",
    "    \"\"\"\n",
    "    num = noise.shape[0]\n",
    "    x_neg_t = noise\n",
    "    x_neg = tf.zeros([self.hps.num_diffusion_timesteps, num, self.hps.img_sz, self.hps.img_sz, 3], dtype=tf.float32)\n",
    "    x_neg = tf.concat([x_neg, tf.expand_dims(noise, axis=0)], axis=0)\n",
    "    is_accepted_summary = tf.constant(0.)\n",
    "\n",
    "    for t in tf.range(self.hps.num_diffusion_timesteps - 1, -1, -1):\n",
    "        x_neg_t, _, is_accepted = self.p_sample_langevin(x_neg_t, t, dropout=0.)\n",
    "        is_accepted_summary = is_accepted_summary + is_accepted\n",
    "        x_neg_t = tf.reshape(x_neg_t, [num, self.hps.img_sz, self.hps.img_sz, 3])\n",
    "        insert_mask = tf.equal(t, tf.range(self.hps.num_diffusion_timesteps + 1, dtype=tf.int32))\n",
    "        insert_mask = tf.reshape(tf.cast(insert_mask, dtype=tf.float32), [-1, *([1] * len(noise.shape))])\n",
    "        x_neg = insert_mask * tf.expand_dims(x_neg_t, axis=0) + (1. - insert_mask) * x_neg\n",
    "    is_accepted_summary = is_accepted_summary / tf.convert_to_tensor(self.hps.num_diffusion_timesteps, dtype=tf.float32)\n",
    "    return x_neg, is_accepted_summary\n",
    "\n",
    "def p_sample_progressive_inner(self, noise):\n",
    "    \"\"\"\n",
    "    Sample a sequence of images with the sequence of noise levels, without tf.function decoration\n",
    "    \"\"\"\n",
    "    num = noise.shape[0]\n",
    "    x_neg_t = noise\n",
    "    x_neg = tf.zeros([self.hps.num_diffusion_timesteps, num, self.hps.img_sz, self.hps.img_sz, 3], dtype=tf.float32)\n",
    "    x_neg = tf.concat([x_neg, tf.expand_dims(noise, axis=0)], axis=0)\n",
    "    is_accepted_summary = tf.constant(0.)\n",
    "\n",
    "    for t in tf.range(self.hps.num_diffusion_timesteps - 1, -1, -1):\n",
    "        x_neg_t, _, is_accepted = self.p_sample_langevin(x_neg_t, t, dropout=0.)\n",
    "        is_accepted_summary = is_accepted_summary + is_accepted\n",
    "        x_neg_t = tf.reshape(x_neg_t, [num, self.hps.img_sz, self.hps.img_sz, 3])\n",
    "        insert_mask = tf.equal(t, tf.range(self.hps.num_diffusion_timesteps + 1, dtype=tf.int32))\n",
    "        insert_mask = tf.reshape(tf.cast(insert_mask, dtype=tf.float32), [-1, *([1] * len(noise.shape))])\n",
    "        x_neg = insert_mask * tf.expand_dims(x_neg_t, axis=0) + (1. - insert_mask) * x_neg\n",
    "    is_accepted_summary = is_accepted_summary / tf.convert_to_tensor(self.hps.num_diffusion_timesteps, dtype=tf.float32)\n",
    "    return x_neg, is_accepted_summary\n",
    "\n",
    "@tf.function\n",
    "def distribute_p_sample_progressive(self, noise, strategy):\n",
    "    \"\"\"\n",
    "    Multi-device distributed version of p_sample_progressive\n",
    "    \"\"\"\n",
    "    samples, is_accepted = strategy.run(self.p_sample_progressive_inner, args=(noise,))\n",
    "    samples = tf.concat(samples.values, axis=1)\n",
    "    is_accepted = strategy.reduce(tf.distribute.ReduceOp.MEAN, is_accepted, axis=None)\n",
    "\n",
    "    return samples, is_accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FLAGS.jobid = 0\n",
    "FLAGS.logdir = ''\n",
    "FLAGS.eager = False\n",
    "FLAGS.ckpt_load = None\n",
    "FLAGS.device = 0\n",
    "FLAGS.tpu = False\n",
    "FLAGS.tpu_name = None\n",
    "FLAGS.tpu_zone = None\n",
    "FLAGS.rnd_seed = 1\n",
    "FLAGS.problem = 'cifar10'\n",
    "FLAGS.n_batch_train = 64\n",
    "FLAGS.lr = 0.0001\n",
    "FLAGS.beta_1 = 0.9\n",
    "FLAGS.n_iters = 1000000\n",
    "FLAGS.grad_clip = False\n",
    "FLAGS.warmup = 1000\n",
    "FLAGS.n_batch_per_iter = 1\n",
    "FLAGS.cosine_decay = False\n",
    "FLAGS.opt = 'adam'\n",
    "FLAGS.eval = False\n",
    "FLAGS.include_xpred_freq = 1\n",
    "FLAGS.eval_fid = False\n",
    "FLAGS.fid_n_samples = 64\n",
    "FLAGS.fid_n_iters = 40000\n",
    "FLAGS.fid_n_batch = 64\n",
    "FLAGS.num_res_blocks = 2\n",
    "FLAGS.num_diffusion_timesteps = 6\n",
    "FLAGS.randflip = True\n",
    "FLAGS.dropout = 0.0\n",
    "FLAGS.normalize = None\n",
    "FLAGS.use_attention = False\n",
    "FLAGS.resamp_with_conv = False\n",
    "FLAGS.spec_norm = True\n",
    "FLAGS.res_conv_shortcut = True\n",
    "FLAGS.res_use_scale = True\n",
    "FLAGS.ma_decay = 0.999\n",
    "FLAGS.noise_scale = 1.0\n",
    "FLAGS.mcmc_num_steps = 30\n",
    "FLAGS.mcmc_step_size_b_square = 0.0002\n",
    "\n",
    "\n",
    "FLAGS.num_diffusion_timesteps = 6\n",
    "FLAGS.img_sz = 32\n",
    "FLAGS.num_res_blocks = 8\n",
    "FLAGS.n_batch_train = 256\n",
    "FLAGS.noise_scale = 1.0\n",
    "\n",
    "diffusion = RecoveryLikelihood(FLAGS)\n",
    "diffusion.init(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diffusion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_33124/2872747809.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mhps\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mFLAGS\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mB\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muniform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mB\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmaxval\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdiffusion\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnum_timesteps\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mint32\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mx_pos\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_neg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnoise\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdiffusion\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mq_sample_pairs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'diffusion' is not defined"
     ]
    }
   ],
   "source": [
    "hps = FLAGS\n",
    "B = x.shape[0]\n",
    "t = tf.random.uniform(shape=[B], maxval=diffusion.num_timesteps, dtype=tf.int32)\n",
    "x_pos, x_neg, noise = diffusion.q_sample_pairs(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_37448/3722888515.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mx_neg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdisp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mis_accepted\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdiffusion\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mp_sample_langevin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_neg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdropout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mhps\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_37448/2085945032.py\u001B[0m in \u001B[0;36mp_sample_langevin\u001B[1;34m(self, tilde_x, t, dropout)\u001B[0m\n\u001B[0;32m    180\u001B[0m     \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0midentity\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtilde_x\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    181\u001B[0m     \u001B[0mis_accepted_summary\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 182\u001B[1;33m     \u001B[0mgrad_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlog_p_y\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgrad_f\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtilde_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstep_size_square\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msigma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mis_recovery\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdropout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    183\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    184\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhps\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmcmc_num_steps\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_37448/2085945032.py\u001B[0m in \u001B[0;36mgrad_f\u001B[1;34m(self, y, t, tilde_x, b0, sigma, is_recovery, dropout)\u001B[0m\n\u001B[0;32m    161\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mGradientTape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtape\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m       \u001B[0mtape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 163\u001B[1;33m       \u001B[0mlog_p_y\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlog_prob\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtilde_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msigma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mis_recovery\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdropout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    164\u001B[0m     \u001B[0mgrad_y\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgradient\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlog_p_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    165\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mgrad_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlog_p_y\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_37448/2085945032.py\u001B[0m in \u001B[0;36mlog_prob\u001B[1;34m(self, y, t, tilde_x, b0, sigma, is_recovery, dropout)\u001B[0m\n\u001B[0;32m    156\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    157\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mlog_prob\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtilde_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msigma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mis_recovery\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdropout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 158\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnet\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdropout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreduce_sum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mtilde_x\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m**\u001B[0m \u001B[1;36m2\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;36m2\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0msigma\u001B[0m \u001B[1;33m**\u001B[0m \u001B[1;36m2\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mis_recovery\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    159\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    160\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mgrad_f\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtilde_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msigma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mis_recovery\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdropout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\project\\douyinv\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    966\u001B[0m           with base_layer_utils.autocast_context_manager(\n\u001B[0;32m    967\u001B[0m               self._compute_dtype):\n\u001B[1;32m--> 968\u001B[1;33m             \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcast_inputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    969\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_handle_activity_regularization\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    970\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_set_mask_metadata\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_masks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_37448/947580874.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, inputs, t, dropout)\u001B[0m\n\u001B[0;32m    215\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mi_level\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnum_resolutions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    216\u001B[0m       \u001B[1;32mfor\u001B[0m \u001B[0mi_block\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnum_res_blocks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 217\u001B[1;33m         \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mres_levels\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi_level\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi_block\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtemb\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtemb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdropout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    218\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    219\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muse_attention\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\project\\douyinv\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    966\u001B[0m           with base_layer_utils.autocast_context_manager(\n\u001B[0;32m    967\u001B[0m               self._compute_dtype):\n\u001B[1;32m--> 968\u001B[1;33m             \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcast_inputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    969\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_handle_activity_regularization\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    970\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_set_mask_metadata\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_masks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_37448/947580874.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, inputs, temb, dropout)\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     97\u001B[0m     \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnonlinearity\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnormalize_2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 98\u001B[1;33m     \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrate\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     99\u001B[0m     \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconv2d_2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\project\\douyinv\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001B[0m in \u001B[0;36mdropout_v2\u001B[1;34m(x, rate, noise_shape, seed, name)\u001B[0m\n\u001B[0;32m   4454\u001B[0m     \u001B[1;31m# NOTE: Random uniform can only generate 2^23 floats on [1.0, 2.0)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4455\u001B[0m     \u001B[1;31m# and subtract 1.0.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4456\u001B[1;33m     random_tensor = random_ops.random_uniform(\n\u001B[0m\u001B[0;32m   4457\u001B[0m         noise_shape, seed=seed, dtype=x_dtype)\n\u001B[0;32m   4458\u001B[0m     \u001B[1;31m# NOTE: if (1.0 + rate) - 1 is equal to rate, then that float is selected,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\project\\douyinv\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\u001B[0m in \u001B[0;36mrandom_uniform\u001B[1;34m(shape, minval, maxval, dtype, seed, name)\u001B[0m\n\u001B[0;32m    293\u001B[0m           shape, minval, maxval, seed=seed1, seed2=seed2, name=name)\n\u001B[0;32m    294\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 295\u001B[1;33m       result = gen_random_ops.random_uniform(\n\u001B[0m\u001B[0;32m    296\u001B[0m           shape, dtype, seed=seed1, seed2=seed2)\n\u001B[0;32m    297\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mminval_is_zero\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\project\\douyinv\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\u001B[0m in \u001B[0;36mrandom_uniform\u001B[1;34m(shape, dtype, seed, seed2, name)\u001B[0m\n\u001B[0;32m    711\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mtld\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_eager\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    712\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 713\u001B[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001B[0m\u001B[0;32m    714\u001B[0m         \u001B[0m_ctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_context_handle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtld\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"RandomUniform\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    715\u001B[0m         tld.op_callbacks, shape, \"seed\", seed, \"seed2\", seed2, \"dtype\", dtype)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "x_neg, disp, is_accepted = diffusion.p_sample_langevin(x_neg, t, dropout=hps.dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss, loss_ts, f_ts = diffusion.training_losses(x_pos, x_neg, t, dropout=hps.dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 4 1 0 0 2 5 1 3 4 0 5 2 2 1 4 3 4 1 5 0 2 0 2 3 5 3 0 0 0 5 1 5 3 3 0\n",
      " 0 5 5 0 1 1 0 3 2 4 2 2 0 4 0 3 0 2 1 3 1 0 3 3 5 4 1]\n",
      "[0.01       0.32368022 0.51649529 0.63221107 0.71324214 0.77336903\n",
      " 0.99974058]\n"
     ]
    }
   ],
   "source": [
    "print(t.numpy())\n",
    "print(diffusion.sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.45381534 1.         0.4185327  0.6266857  1.         1.\n",
      " 0.51198125 0.3237642  0.6266857  0.45381534 0.4185327  1.\n",
      " 0.3237642  0.51198125 0.51198125 0.6266857  0.4185327  0.45381534\n",
      " 0.4185327  0.6266857  0.3237642  1.         0.51198125 1.\n",
      " 0.51198125 0.45381534 0.3237642  0.45381534 1.         1.\n",
      " 1.         0.3237642  0.6266857  0.3237642  0.45381534 0.45381534\n",
      " 1.         1.         0.3237642  0.3237642  1.         0.6266857\n",
      " 0.6266857  1.         0.45381534 0.51198125 0.4185327  0.51198125\n",
      " 0.51198125 1.         0.4185327  1.         0.45381534 1.\n",
      " 0.51198125 0.6266857  0.45381534 0.6266857  1.         0.45381534\n",
      " 0.45381534 0.3237642  0.4185327  0.6266857 ], shape=(64,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64,), dtype=float64, numpy=\n",
       "array([0.66666667,       -inf, 0.75      , 0.        ,       -inf,\n",
       "             -inf, 0.5       , 0.8       , 0.        , 0.66666667,\n",
       "       0.75      ,       -inf, 0.8       , 0.5       , 0.5       ,\n",
       "       0.        , 0.75      , 0.66666667, 0.75      , 0.        ,\n",
       "       0.8       ,       -inf, 0.5       ,       -inf, 0.5       ,\n",
       "       0.66666667, 0.8       , 0.66666667,       -inf,       -inf,\n",
       "             -inf, 0.8       , 0.        , 0.8       , 0.66666667,\n",
       "       0.66666667,       -inf,       -inf, 0.8       , 0.8       ,\n",
       "             -inf, 0.        , 0.        ,       -inf, 0.66666667,\n",
       "       0.5       , 0.75      , 0.5       , 0.5       ,       -inf,\n",
       "       0.75      ,       -inf, 0.66666667,       -inf, 0.5       ,\n",
       "       0.        , 0.66666667, 0.        ,       -inf, 0.66666667,\n",
       "       0.66666667, 0.8       , 0.75      , 0.        ])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_scale = 1.0 / (tf.cast(tf.gather(diffusion.sigmas, t + 1), tf.float32) / diffusion.sigmas[1])\n",
    "print(loss_scale)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}